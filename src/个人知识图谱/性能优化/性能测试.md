### 性能测试
#### 性能测试目的 
- 确保软件应用程序在一定的负载流量下运行良好
- 目标： 发现和性能相关的各种问题和性能瓶颈，从而进一步去消除错误和性能瓶颈
- 测试的目的：
    - 测量服务速度（Speed）： 延迟和吞吐率
    - 测量可扩展性（Scalability）： 
    - 测量稳定性（Stability）
    - 测量性能瓶颈（Performance Bottleneck）
- 测试的负载流量
    - 低流量、中等流量和高流量 --> 相对于生产环境中的流量
    - 负载变化的速度
    
#### 测试的分类
- 耐力测试 （偏重点是测试时间）    
    - 长时间测试具有预期负载量的系统，以验证系统的行为是否正常
    - 暴露某些不易重现的问题，如内存问题、系统故障或其他随机问题 
- 基准测试/性能回归测试
    - 保证前后测试环境的一致，比如负载流量的特征和大小
- 负载测试（Load Testing）
    - 验证被测试系统或者程序是否可以处理预期的负载流量
    - 并验证正常和峰值负载条件下的系统和程序行为
- 断点测试（Breakpoint Testing）
    - 随着时间的推移而增大流量负载，同时监视系统的预定故障条件
    - 用来确定系统将达到其所需规范或服务水平协议的最大容量
- 尖峰测试（Spike Testing）
    - 确定系统在负载（比如用户请求数）突然变化时的系统行为
    - 核心是负载变化的突然性，所以也算是一种压力测试
- 可扩展性/可伸缩性测试
    - 确定一个程序和系统的非功能性特征能不能在变化的环境里合理扩展
- 容量测试（Capacity Testing）
    - 确定一个单位容量能够支持的最大负载   
    - 容量测试至少包含三个部分：可调节的流量负载、性能的测量、可以接受的性能指标。
- 瓶颈测试（Bottleneck Testing）
    - 目的是找到被测试系统和程序的最制约的资源类型（比如 CPU 或者存储）

#### 性能测试规划和执行
- 首先搞清楚被测试的实体，也就是 SUT（System Under Test），对应的性能指标和度量，以及期望的结果
    - ![image](../../ref_images/20200215/72857508b6a54ce2da0467ce9249c138.png)
    - 测试过程中，除了 SUT 本身，其他所有的模块和构件在整个性能测试的过程中都不能有任何性能瓶颈
- 测试规划中需要考虑的问题
    - 负载流量的特征： 需要决定是用真正的生产环境的负载还是仿真的负载
    - 负载如何注入
        - 是用实时的流量呢，还是用过去捕捉的流量来重新注入？
        - 流量的大小，是完全模拟生产环境呢，还是加大负载。
        - 如果不使用实时生产流量，那么如何注入呢
    - 测试的数据： 用真正的用户数据还是仿真的数据
    - 黑盒还是白盒测试
        - 白盒： 允许改变 SUT，比如在程序中间输出更多的性能日志信息等
    - 测试的工具
    - 测试的环境
- 测试执行时需要考虑的问题
    - 测试结果的可重复性非常重要
    - 分步进行：把复杂的测试验证过程分成几步，一次验证一步，最后一步是整个完整的测试
    - 先短时间测试，再长时间测试
    - 模拟测试：在实际使用负载测试之前，先执行简单的负载测试以检查各种工具的正确性      

#### 测试的场景及工具的选择
-  性能测试的一般过程是：
    - 通过录制、回放定制的脚本，模拟多用户同时访问被测试系统（SUT）来产生负载压力
    - 同时监控并记录各种性能指标
    - 最后生成性能分析结果和报告
    - 从而完成性能测试的基本任
- 测试工具包括的模块
    - 负载生成模块
    - 测试数据收集模块
    - 结果分析和展示
    - 资源监控模块
    - 控制中心模块
    - ![image](../../ref_images/20200215/1c4e724cff73f9595bb63b49a5cd3a4f.png)
- Web 测试场景
    - JMeter
    - LoadRunner
    - Locust 突出优点是可扩展性很好 
- 系统测试场景
    - UnixBench
    - Perf  
- 数据库测试场景
    - SysBench
    - mysqlslap 
- 文件 IO 和存储测试场景 
    - ioZone 
    - Bonnie++
    - dd
- 网络测试场景
    - Netperf
    - Iperf 
- 移动 App 测试场景
    - 平台生态系统，现在主要有安卓 Android 和 iOS，比如 Appium  
    - adb
    - Monkey 
    
#### 保证测试结果可靠且可重复的经验和教训
- 测试规划类
    - 详细记录测试环境和测试过程（最好是自动记录），包括操作系统和程序的版本号，以及各种软件参数的设置等
    - 快速地复位测试环境，缓存也清空
    - 足够的负载请求和数据，注意保证它们的多样化和代表性
- 测试进行类
    - 性能数据日志要适当输出，要实时输出有关的性能数据和日志，比如 CPU 使用率数据
    - 测试环境要稳定
    - 一次调一个参数的利弊
- 结果分析
    - 根因分析要由易到难，从最明显的性能瓶颈来开始，往往可以事半功倍
        - 首先从最常见的几种资源和几个指标查起，比如 CPU 使用率、存储 IO 繁忙度、内存大小、网络发送和接收速度等
        - 进一步的分析就可以针对不太明显的资源，比如内存带宽，缓存击中率，线程加锁解锁等
        - 应用程序和系统的一些配置参数
        - 应用业务瓶颈，如 SQL 语句、数据库设计、业务逻辑、算法、数据等
    - 几种测试最好互相验证
    - 测试结果和生产环境比较，尤其要注意的是网络环境的差异 
        - 人为地添加停顿来模拟思考时间模拟真实客户的操作流程
 
 ### 性能测试工具
 #### ab
 #### JMeter
 #### LoadRunner