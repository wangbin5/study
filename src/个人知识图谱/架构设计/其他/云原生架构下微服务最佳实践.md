### 云原生概述
- 云原生的属性
    - 分布式
    - 弹性
    - 多租户
    - 自服务
    - 按需计量和计费
    - 增量部署和测试
- 云原生的目标
    - 可扩展性/可伸缩性
    - 高可用性：更新是可用性的天敌
    - 敏捷，加快研发速度
    - 效率
- 云原生架构原则
    - 不变性： 实例一旦部署，就不能修改；只能创建/移除实例
    - 关注点分离： 提升系统扩展性和可用性
    - 反脆弱性： 面向失败设计
    - 高信任的组织
    - 共享
- 云原生的组成
    - 技术
    - 流程
    - 文化
    - 架构角度： 以云和微服务架构为基础构建系统
- 云原生成熟度模型
    - 第1级：
    - 第2级：
    - 第3级：
    - 第4级：
- 云原生的原则
    - 为失败设计原则
    - 不变性原则： 替换的速度远大于修复的速度
    - 去中心的原则： 
        - 开发团队独立自主，尝试询问： 服务是否经常必须经过团队外部人员审批才能上线 ？ 
    - 标准化原则： 通过框架固化标准，通过工具监测标准
    - 速度优先原则
        - 效率 --> 节流
        - 速度 --> 开源
        - 为了减少依赖，是系统更独立 --> 允许重复代发，重复开发
    - 简化设计原则
        - 如果设计满足了所有的要求，说明一定过度设计了
        - 重要监测方法： 产品经理的所有想法都实现了吗 ？ 不合理的业务实现是否在发布到线上前被否定 ？
    - 自动化驱动原则： 任何重复性的工作都应该自动化
    - 演进式设计原则： 初级阶段应该采用尽可能简单的架构
- Cloud Native 的基石
    - 微服务架构
    - 敏捷基础设施
    - 公共基础服务

### 微服务架构
- 微服务架构与单体架构对比
    - 可扩展性
        - 微服务架构 高，符合AKF扩展立方体的Y轴扩展
        - 单体架构   低，只能做到X轴扩展
    - 一致性实现成本： 
        - 微服务 高
        - 单体   低
    - 时延
        - 微服务 高
        - 单体   低
    - 关联查询复杂度
        - 微服务 高
        - 单体   低
- 开始微服务架构的时机
    - 将单体架构中逐步划分服务，比从一开始就构建微服务要简单的多
    - 资源受限的情况下，采用微服务架构风险较大
    - 业务复杂到一定程度后，微服务机构的优势才会体现
- 微服务粒度决策依据
    - 微，不代表足够小，应该解释为合适
    - 团队规模
    - 交付速度要求
    - 其他
- 微服务设计原则
    - 垂直划分优先原则（业务划分）
        - 水平划分缺点：
            - 调用次数多，性能大幅下降
            - 实现一个功能，要跨更多服务，沟通效率低
    - 持续演进原则
    - 服务自治、接口隔离原则： 数据库不共享
    - 自动化驱动原则
- 实现微服务的先决条件
    - 自动化工具链
    - 微服务框架
    - 快速申请资源
    - 故障发现及反馈机制
    - 研发流程前的转变
- 单体拆分的准备工作
    - 先做好模块解耦
    - 状态外置
        - 无状态不代表状态消失，只是把状态转移到分布式缓存或数据库中
        - 优点是：复杂度抽象到统一的位置，便于集中处理
        - 需要拆分的状态分类
            - 定时任务
            - 本地存储
            - 本地缓存
    - 去触发器、存储过程： 减轻数据库的压力
    - 通过接口隔离
- 微服务划分方法
    - 基于业务复杂度划分
    - 基于数据驱动划分
    - 基于领域驱动划分微服务（推荐）
        - 关键问题
            - 一次更新如果要跨越多个服务，那么一致性要求是什么 ？
            - 跨服务查询，是否做关联查询，一个服务内部是否能解决问题 ？
            - 性能是否能满足要求
            - 成本是否能满足要求
- 单体拆分成微服务的步骤
    - 第一步：前后端分离
    - 第二步：提取公共服务
    - 第三步：不断从老系统中提取服务，垂直划分优先
    - 第四步：API Gateway 适当做水平切分
    - 优先抽象核心服务，因为微服务的开发及运维成本比较高，不是所有的服务都需要拆分成小粒度
- 衡量服务拆分合理性的方法
    - 多个维度综合考虑
    - 小功能的修改从需求到上线需要多少时间 ？
    - 大多数修改是否能在一个服务内完成 ？ 
    - 是否需要频繁修改接口 ？
    - 响应时间能否满足要求 ？
    - 是否存在大量的跨服务更新 ？
- 微服务API设计原则
    - 简单
    - 易懂
    - 一致
    - 稳定
    - 安全
    - 提供给第三方，需要考虑如何认证、租户间如何隔离，尽量使用https
- Http/2是基于二进制的
- 微服务框架的重要功能
    - 服务治理
    - 容量规划
    - 高效通信: 序列化、反序列化、支持并行、异步、非阻塞转换，支持多语言
    - 负载均衡：Lvs等软负载均衡很难扩展及实现个性化需求
- 服务独享数据库
    - 服务拆分的原因可能是受到数据库扩展性的制约
    - 分表之前，先进行分库，垂直拆分是这个阶段必背良药
    - 两种情况下允许共享数据库
        - 单体架构迁移到微服务架构的过度阶段
        - 小规模部署过程中

### 敏捷基础设施
- 传统基础设施面临的挑战
    - 资源利用率低
    - 服务器数量呈爆炸性增长
    - 没有标准化
    - 脆弱的基础设施，缺乏自动化，配置服务器慢
- 基础设施即代码，可编程基础设施
    - 全部自动化，通过容器封装环境，开发人员可以将所有软件和依赖直接封装在容器里，打包成镜像，生产环境直接部署镜像
    - 通过容器实现开发、测试、生产环境的一致
    - 很多失败的案例都是由于利益之争，一个有效的策略是让有代码能力的运维人员去开发云平台和工具，没有代码能力的运维人员做基础运维
- 敏捷基础设施的目标是
    - 标准化
    - 可替换
    - 自动化
    - 可视化
    - 可追朔
    - 快速

### 公共基础服务
- 监控服务
    - 传统监控更强调以资源为中心，如： CPU、内存、带宽等
    - 以应用为中心的监控，如： 错误率、响应时间、业务指标等
    - 使用时序数据库存放监控数据，流行的时序数据库有： InfluxDb、OpenTSDB、Druid、Graphite
    - Prometheus + Grafana 监控
- 分布式消息中间件服务
    - 数据库是整个系统最难扩展的地方
    - RabbitMQ、Kafka、RocketMQ
- 分布式缓存服务
    - 缓存分为本地缓存、分布式缓存
    - 分布式缓存的优点
        - 不需要在各个业务节点间同步数据
        - 能够做到业务服务无状态、更容易扩展
        - 不需要管理数据，本地缓存会导致Full GC
    - 本地缓存的优点
        - 性能更好，不需要维护额外的缓存服务
    - 适合放进分布式缓存的数据特点
        - 数据量比较小，某些场景下，需要对数据进行剪裁
        - 不经常变化的数据，且访问量大，读写比例高
        - 计算代价比较高的数据
        - 热点核心数据
    - 不适合放入缓存的数据
        - 变化比较快的数据
        - 要求强一致的数据
    - 缓存内存分配策略
        - 时间换空间： 需要时动态分配内容
        - 空间换时间： 预先分配好内存
    - Redis集群模式
        - 热点问题在分布式缓存中很关键
        - 客户端模式
            - Zookeeper 或 ETCD 作为注册发现服务
            - 自动将数据集分到多个节点
            - 高可用
            - 扩容可以使用presharding、数据迁移两种方式，利用slot机制迁移数据
            - 优点是客户端直连redis，性能好；缺点是sdk升级复杂
        - 代理模式，如：Twemproxy/Codis
            - 优势： 1）控制力强 2）使用简单 3）收敛连接数
            - 缺点是性能有损耗
        - SideCar模式
            - proxy节点和业务服务部署在一起
            - 比代理模式性能好，但是业务开发人员的复杂度增加了，需要额外部署proxy节点
        - 无中心模式
            - 节点间通过gossip协议同步信息
            - 优势：
                - 无中心架构绝对的去中心化，元数据存储在所有节点上
                - 部署简单
                - 不经过代理，性能高
            - 缺点：
                - sdk过重，升级麻烦
                - 缺少友好的界面管理
                - 以节点为单位，分区不够小，热点问题严重
                - 不一致问题
                - 不够自动化，节点变动、数据迁移都需要执行命令完成
                - Gossip协议导致的性能问题
            - 不适合大规模集群
        - Redis 4.0 新功能
            - 模块化
            - 部分复制
            - 混合RDB-AOF模式
- 分布式任务调度服务
    - 至少满足以下要求
        - 不重复执行任务
        - 不遗漏执行任务
    - tbschedule
    - Elastic-job
- 分布式ID生成: 建议使用Snow flake 


### 可用性设计
- 降低可用性的原因
    - 发布
    - 故障
    - 压力
    - 外部强依赖（同步调用）
- 高可用设计方法
    - 20/10/5 以实际流量的20倍来设计，实际流量10倍来开发系统，实际流量5倍来部署系统
    - Design for failure
- 发布
    - 影子测试： 在生产环境通过流量复制、回放和对比的测试方法
    - 蓝绿发布
    - 灰度发布
- 容错设计
    - 消除单点: 
        - 两次失误高度
        - 为避免升级时，节点出现故障，要求部署节点数是 满足流量部署的节点数+2
    - 特性开关：建立通用的特性开关机制，如： 阿里的switch
    - 服务分级
        - 分级标准，发生故障时
            - 1级服务： 直接导致业务遭受重大损失
            - 2级服务： 用户体验受到严重影响
            - 3级服务： 用户体验受到轻微影响
            - 4级服务： 管理维护服务，用户不会受到影响 
        - 电商的服务分级示例
            - 1级服务： 下单服务、价格服务、库存服务
            - 2级服务： 评论服务、搜索服务、物流服务
            - 3级服务： 推荐服务、个人信息、积分服务
            - 4级服务： 报表统计、舆情分析
    - 降级设计
        - 关闭某个功能
        - 请求短路，直接返回缓存数据
        - 简化流程，放弃某个操作
        - 延迟执行，停止定时任务
        - 降级的前提是对服务进行分级
    - 超时重试
        - 请求的状态分为成功、失败、超时三种
        - 超时设置中重要的参数： 超时时间、重试次数、重试间隔时间、重试间隔时间的衰减度
        - 超时重试模式
            - try-catch-redo
            - spring tryer： 注解@Retryable @Backoff @Recover
            - guava retrying
    - 隔离策略 
        - 隔离是在系统发生故障时，显示传播范围和影响范围，特别是非核心系统的故障对核心系统的影响
        - 线程池隔离
        - 进程隔离
        - 集群隔离：终端用户使用的集群和管理员使用的集群分离
        - 用户隔离：
        - 租户隔离
            - 逻辑隔离
            - 物理隔离
            - 混合隔离
    - 熔断器
        - 服务雪崩现象
        - 熔断器模式
        - 使用熔断器需要关注的问题
            - 熔断器打开时，生产者如何应对 ？ 比如： 快速失败、业务降级使用缓存数据 ？
            - 和运维系统关联使用，可以手动控制熔断器状态
            - 禁止一个熔断器控制多个服务
    - 流控设计
        - 限流对于对外开放的接口尤为重要
        - 系统存在多个租户时，要针对每个租户限流，保证其他租户不受影响
        - 限流算法
            - 固定窗口算法： 效果不理想，大量消费请求涌入，容易出现踩踏事件
            - 漏桶算法
            - 令牌桶算法： 允许某种程度的突发流量
                - Guava Ratelimit
        - 流控位置
            - 请求入口处： 网关 nginx
            - 业务服务入口处： 设置最大连接数、最大线程数实现限流
                - 每个业务服务都应该声明SLA，包括单位时间处理请求的能力
            - 公共基础服务： 数据库、缓存
        - redis实现分布式限流
    - 容量预估
        - 全链路压测，复制线上流量
        - 数据库数据使用影子表进行隔离
        - 要点
            - 找到核心流程，全链路压测成本高，只对核心流程做。
            - 选择隔离方式： 独立环境 & 生产混合环境
            - 缩小依赖范围
    - 故障演练
    - 数据迁移
        - 逻辑分离，物理不分离： 优点简单，缺点隔离性差，容易引发全局故障
        - 逻辑分离，物理分离： 优点隔离性好，缺点是数据同步比较复杂

### 可扩展性设计
- 关键问题： 增加机器能否解决问题
- AKF扩展立方体
    - X轴扩展： 
        - 通过复制实例+负载均衡实现
        - 服务早期，无状态服务可以X轴扩展，有状态服务不能
    - Y轴扩展
        - 服务拆分，从单体架构-->微服务架构
        - 适合业务逻辑复杂，数据关联性不是特别强
        - 运维复杂度高、实现一致性成本高
    - Z轴扩展
        - 数据（状态）分片，通过分片减少单节点压力
        - 大型分布式系统，存在并发压力且X轴、Y轴扩展无法解决问题
        - 架构复杂，数据迁移复杂，实现成本高
- 扩展数据库的方法
    - X轴： 主从复制集群
    - Y轴： 分库&垂直分表
    - Z轴： 水平分表
        - 重新均衡代价昂贵，最好避免
        - 水平分表应该是最后一个选择
    - 关联查询处理方式
        - 建立多维度数据库，电商中普遍使用
            - 优势： 架构简单
            - 问题： 
                - 存在数据不一致的风险
                - 综合表庞大，可能成为性能瓶颈
        - 外部搜索引擎：应用广泛
        - 分布式缓存： 常在SNS类系统综合查询中使用
    - 分片扩容方案
        - 方案1：停服扩容
            - 1）停服，备份数据库
            - 2）增加数据库节点，导入备份数据
            - 3）修改数据库中间件配置，分片规则改为 原数据库+新加数据库
            - 4）删除冗余数据
        - 方案2：基于数据库的0中断扩容
            - 1）备份数据库
            - 2）将新加数据库设置成原数据库的从节点，同步数据
            - 3）修改数据库中间间配置，禁止写入，等主从数据一致
            - 4）修改数据库中间件配置，分片规则改为 原数据库+新加数据库
            - 5）修改数据库中间间配置，允许写入
            - 6）删除冗余数据
            - 写中断时间在分钟级别
        - 方案3：基于数据库中间间的0中断扩容
            - 1）备份数据库
            - 2）将新加数据库设置成原数据库的从节点，同步数据
            - 3）修改数据库中间间配置，禁止修改删除，插入操作双写，等主从数据一致
            - 4）修改数据库中间件配置，分片规则改为 原数据库+新加数据库
            - 5）修改数据库中间间配置，允许修改删除操作
            - 6）删除冗余数据

### 高性能 
- 常用工具： dstat、sar、netstat、tcpdump、lsof
- 服务通信优化
    - 同步转异步
    - 阻塞转非阻塞
    - 序列化
- 使用消息中间件提升写性能
    - 数据库单机吞吐量在1000TPS左右
    - 消息中间件在几万到几十万
- 通过缓存提升读性能
    - Guava Cache
    - Redis
    - 常用模式
        - Cache Aside
            - 读操作
                - 判断是否在缓存中，
                - 在： 读取缓存后返回
                - 不在：从数据库加载，放入缓存后返回
            - 写操作
                - 信息同步到数据库
                - 从缓存删除数据
            - 也存在缓存中出现旧数据的可能，但是出现的概率低
            - 推荐先更新数据库，再删除缓存
        - Cache as Sor
            - 将缓存和数据库看成一个整体
            - Read Through： 和Cache Aside 类似
            - Write through：
                - 写数据时，如果缓存没有命中，应用直接写数据库，否则更新缓存数据，由缓存写数据库
            - Write Behind Caching
                - 和linux page cache 类似
                - 应用只写缓存，由缓存写数据库
                - 可以实现批量合并更新，缺点是可能丢失数据
    - 缓存的场景问题
        - 为缓存数据设置合理的失效时间
        - 设置合理的回收策略
        - 缓存预热： 缓存的失效时间要能错开，不能一起失效
- 数据库优化的方法（按照优先级排序）
    - 索引、冗余、批量写入
    - 减少锁粒度
    - 减少复杂查询
    - 适当转移事务处理
    - 提升硬件性能
        - 使用SSD 硬盘/PCID-flash硬盘
        - 待补充： 磁盘阵列
    - 读写分离
    - 分库
    - 垂直分表
    - 水平分表
    - 根据业务情况选择其他数据库： Nosql、时序数据库
- 简化设计
    - 架构需要全方面考虑
        - 需要考虑架构的复杂度，以及带来的成本
        - 权衡代码的可读性和可维护性
        - 考虑需求是否合理，能否从业务的角度解决问题
    - 转移复杂度的例子，如：抢红包业务
        - 如果通过锁来实现，数据库压力大 ，改为 应用内对请红包请求排序，串行修改数据库
        - 拆红包时计算红包大小 改为 发红包时计算红包大小，减少计算量
    - 从业务角度优化，比如12306网站
        - 分段放票，将一次秒杀分为多次
        - 票的剩余数量可以使用 有票、无票 等文字替代
        - 查询时允许数据不准确，采用排队的方式，满足最终一致性


### 一致性问题
- 一致性问题在大多数场景下发生的概率低，处理难度大；在大部分场景下放弃一致性
- 强一致性需要极大的成本，要根据系统的容忍度适当放宽一致性的要求
- 以数据为中心的一致性模型
    - 从数据存储的角度出发，包括数据库、文件等
    - 严格一致性
        - 写操作能够立刻同步到其他进程，任何读操作都能读取最新的数据
    - 顺序一致性
        - 所有进程以相同的顺序看到所有的修改
    - 因果一致性
        - 所有进程必须以相同的顺序看到具有潜在因果关系的写操作
    - FIFO一致性
        - 要求所有进程以某个单一进程提出写操作的顺序看到这些写操作
    - 弱一致性： 不保证数据同步的时间，执行同步操作后，可以看到最新的值
- 以用户为中心的一致性模型
    - 单调读一致性
        - 一个进程读取数据项的值，后续读取改数据项的值，不能比之前的值旧
    - 单调写一致性
        - 一个进程对数据项的写操作，必须在该进程对数据项的后续写操作之前完成
    - 写后读一致性
        - 一个进程对数据项的写操作，总会被该进程对数据项的读操作看到
        - Mysql规定写后t时间读master的数据，t 大于mysql主从延迟时间
    - 读后写一致性
        - 一个进程对数据项读操作之后执行的写操作，只会发生在数据项值与读取值一致或更新的副本上
- 在实际使用过程中一致性的分类
    - 弱一致性
    - 最终一致性
        - 在时间窗口后，各个副本的数据一致
        - 异步更新副本的数据
    - 强一致性
        - 同步更新副本的数据
- 实现强一致性的方法
    - 两阶段提交
    - 三阶段提交
    - 缺点
        - 无法保证绝对的强一致性
        - 性能低下，扩展性受到限制
        - 架构复杂
        - 业界缺乏大规模应用的案例
- 实现最终一致性的方法
    - 推荐使用最终一致性
    - 方案1：重试机制
        - 多级重试需要避免叠加效应
    - 方案2：本地记录日志
        - 缺点：服务编程有状态
    - 方案3: 可靠消息模式
        - 事件发布到MQ，就任务写操作成功
        - 加入事件表，把分布式事务变成单库事务
        - 优势
            - 提升了吞吐量
            - 降低了响应时间
        - 缺点
            - 存在不一致的时间窗口（可能是致命问题）
            - 导致了架构的复制性
            - 消费者需要保证幂等性
    - 方案4:Sage 事务模型
        - 核心思想是将一个长事务拆分成多倍本地事务来实现
        - 每个业务都要实现正向、负向两个接口
        - 出现不一致可以人工干预
    - 方案5：TCC模型
- 分布式锁
    - 并发控制机制，解决并发导致的冲突问题
    - 数据库悲观锁、乐观锁
    - zookeeper 分布式锁
    - redis 分布式锁
    - redis 集群锁方案：RedLock
        - 重启导致锁失效，可以通过延迟重启解决
        - 任何时候都要在全部节点上删除锁，即使加锁失败
- 保证幂等性的方法
    - 幂等令牌： 客户端携带唯一key作为令牌，服务端记录key对应请求的执行状态，避免重复请求
    - 可以考虑在数据库中增加流水表（key列设置唯一性约束）的方式来保证幂等下

### 研发流程
- 一般代码审查速度为150行/小时
- 开发人员自服务
    - 开发过程中，少交流、少沟通、少开会且不会导致做错，就是最高的效率
- 代码即设计