#### 提高系统可用性的要点
- 时刻考虑应对故障
    - 设计时考虑如何应对故障
        - 使用设计模式提高系统的可用性
            - 捕获底层异常
            - 重试
            - 断路器            
    - 依赖出现故障时的应对
    - 用户数据出现故障时的应对
        - 流量突增
- 时刻考虑如何伸缩
    - 设计出能够增加数据库数量和容量的架构
    - 考虑限制数据伸缩的原因
    - 能够通过增加应用程序服务器，增大系统的响应容量
    - 静态流量导向离线提供方，如CDN 
    - 考虑静态生成部分动态资源
- 缓和风险
    - 存在系统崩溃的风险
    - 存在数据库崩溃的风险
    - 存在返回结果不正确的风险
    - 存在网络连接失败的风险
    - 存在新部署软件功能出现故障的风险
- 监控可用性
    - 服务器监控
    - 配置变化监控
    - 应用程序性能监控
    - 人为测试
    - 报警
- 以预测和确定的方式应对可用性问题
    - 为常见故障问题提供标准化流程  
    
#### 可用性的测量方法
- 可用性 = （总时间- 不可用时间）/ 总时间
- N个9，通常至少要有3个9
    - 3个9    43分钟
    - 4个9    4分钟
    - 5个9    26秒
- 要考虑计划中和维护工作时，导致的系统不可用

#### 提高可用性的方法
- 提高可用性的步骤 
    - 测试并跟踪当前的可用性
    - 使用跟踪系统发现的问题，制定计划改进系统
    - 时刻关注可用性
- 最佳实践： 手动流程自动化
    - 自动化部署
    - 配置管理
    - 具有回滚能力的自动化变更流程
    - 自动化的变更完备性测试


#### 风险管理
- 构建高可用系统，主要就是考虑如何管理风险
- 目的：在消除风险的成本与风险发生的成本之间保持平衡
- 风险管理方法
    - 识别风险
        - 列出已知的风险，包括功能模块、风险发生时的危害性和风险发生的可能性 --> 风险模型
        - 分类： 可能性+严重性，分别分为 高 中 低 三个层级
        - 风险模型的重要字段
            - 风险id
            - 系统
            - 所有人
            - 风险描述
            - 标识日期
            - 可能性
            - 严重性
            - 风险缓和计划
            - 状态
            - 监控
            - 风险发生时的处理计划
        - 风险模型的作用域是整个团队
        - 风险模型的创建方法
            - 头脑风暴建立风险列表
                - 来源：开发团队、售后支持、安全威胁、待完成功能列表、性能、业务负责人、相关团队、系统和流程、技术债务
            - 填写可能性、严重性字段
            - 填写风险项详情，分配风险id
            - 制定缓和计划和风险发生时的处理计划（可以只为高风险项制定）
        - 维护风险模型，1个月（最少一个季度）维护一次
            - 增加新的风险
            - 删除旧的过时的风险
            - 更新可能性和严重性
            - 优先检查优先级高的风险
            - 时间允许，继续检查优先级低的风险
        - 与团队成员（开发、测试、运维、产品、管理团队）共享风险模型  
    - 消除最严重的风险
        - 处理范围： 最严重的风险
    - 风险缓和
        - 处理范围： 全部风险
        - 思考有没有降低风险发生几率或降低影响程度的方法        
        - 风险缓和的方法
            - 恢复计划
                - 当风险发生时，处理和修复风险锁造成的影响和问题
                - 不会影响可能性，降低风险的严重性
                - 采取措施的类型
                    - 尽可能迅速的停止问题的行为，如： 服务器重启
                    - 降低问题影响的临时行为，如：微服务的fallback模式
                    - 上报问题的流程，已经通知公司的内部人员，如：onCall                
            - 容灾计划：
                - 在某种灾难发生时，需要采取的措施，如： 多地数据中心应对地质灾难
        - 恢复计划/容灾计划实战： 比赛日模式
            - 服务器故障
            - 网络分区
            - 数据中心故障
            - 随机故障 Netflix的捣乱的猴子
    - 定期检查


#### 微服务处理伸缩性问题
- 微服务的独立性
    - 独立的代码库
    - 独立的数据库
    - 向其他服务提供能力
    - 消费其他服务的能力
    - 单一所有者
- 微服务边界的确定方法
    - 特定的业务需求
        - 法律、监管要求
        - 安全
        - 更加严格的测试要求
        - 限制性访问    
    - 清晰和独立的团队所有权        
    - 天然隔离的数据
    - 共享的能力/数据
- 拆分服务的影响
    - 减少单个服务的复杂性
    - 增加系统整体的复杂性
    - 服务拆分需要适当的平衡
- 微服务服务故障处理方式
    - 级联式的服务故障
    - 依赖服务的故障处理方式
        - 可预测的            依赖服务故障 --> 返回错误提示信息；慢请求、超时问题等
        - 可理解的            响应在API约定之内
        - 合理的
    - 依赖系统故障的模式
        - 乱码响应
        - 表示致命错误发生的响应
        - 结果可理解，单时所需的结果不匹配
        - 结果超出预期范围
        - 没有收到响应      --> 设置请求超时时间
        - 接收响应很慢    
    - 解决方法
        - 优雅降级/补偿   --> 即使依赖服务不可用，也尽可能提供服务价值
        - 尽早失败        --> 提前校验用户的请求： 输入合法性、数据合理性
            - 增加约束条件，比如： 列表请求最多只能请求前20页        
        
#### 考虑节点失败时的容量评估
- 失败恢复过程中，再次发生失败时的处理措施
- 例子： 容量评估里丢失一个节点的情况
    - 假设1个节点处理能力是300，目标处理1000个请求
    - 如果部署4个节点，则当1个节点错误，剩余节点无法满足目标处理能力（300*3 < 1000）
    - 如果部署5个节点，当1个节点错误，剩余节点可以满足目标处理能力
    - 部署5个节点，在滚动升级过程中，如果节点发生故障，则剩余节点无法满足目标处理能力（5-1-1）*300 <1000 
    - 考虑到滚动升级，必须部署6个节点


#### 服务分级
- 以服务的重要性（分为4个级别）为服务打标签
    - 1级服务，关键服务，故障会导致业务产生重大损失
        - 比如： 登录服务、支付服务、权限服务、订单服务
    - 2级服务，对业务比较重要，但不如1级服务；故障会显著影响用户体验
        - 比如： 搜索功能
    - 3级服务，故障会对用户造成细小、不一察觉的影响
        - 比如： 用户头像服务、推荐服务    
    - 4级服务，故障不会对用户造成任何严重的影响
        - 比如： 销售报告生成服务
- 使用服务分级
    - 期望
    - 响应性
        - 是否需要发送报警通知
        - 期望的SLA
        - 低优先级问题的上报路径
        - 响应的时间安排
        - 是否提供紧急部署或产品更改
        - 根据服务的可用性和响应性制定SLA
    - 依赖
- 服务等级协议（SLA） 提供某种级别可靠性和性能的承诺
    - 调用延迟   TP99 < 20ms
    - 流量
    - 运行时长
    - 错误率
         
     
